{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a0921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source code\n",
    "import random\n",
    "from interface.node_interface import Src\n",
    "\n",
    "class source_aish(Src):\n",
    "    def run(self, Ain=None, Aout=None, argCfg=None):\n",
    "        # Example: generates a random number based on `argCfg` settings and stores it in Output Accumulator (Aout)\n",
    "        # Customize to read data from various sources (e.g., blob storage, filesystem, datastream, etc.) and place it in Aout.\n",
    "        # Description:\n",
    "        # - `Ain`: Input accumulator (not typically used in source nodes, but passed for consistency)\n",
    "        # - `Aout`: Output accumulator where generated data is stored\n",
    "        # - `argCfg`: Configuration dictionary containing parameters specific to the node's operation\n",
    "        \n",
    "        acc_key =  argCfg.get(\"data_key\", \"default_data_key\")\n",
    "        \n",
    "        # Generate random data - range can be configured in argCfg\n",
    "        data_min = argCfg.get(\"data_min\", 1)\n",
    "        data_max = argCfg.get(\"data_max\", 100)\n",
    "        random_number = random.randint(data_min, data_max)\n",
    "        \n",
    "        # Store generated data in the output accumulator with configured key\n",
    "        Aout.write(acc_key, random_number)\n",
    "        print(f\"Source node generated and stored data: {random_number} in {acc_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2141ff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers\n",
    "# Add the headers here\n",
    "from interface.accumulator_interface import Accumulator\n",
    "#from ai_forge_client.src.accumulator.file_acc_dev import DevFileAcc\n",
    "#from ai_forge_client.src.accumulator.df_acc import DataFrameAcc\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a7cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test env setup\n",
    "# Test the created node here\n",
    "class LoadBalancer:\n",
    "    def getDataInstance(self):\n",
    "        pass\n",
    "class Pipeline:\n",
    "    def getloadbalancer(self):\n",
    "        return LoadBalancer()\n",
    "\n",
    "def test():\n",
    "    base_path = Path.cwd().resolve().parents[1]\n",
    "    data_folder_in = base_path / \"data/acc_in_folder\"\n",
    "    data_folder_out = base_path / \"data/acc_out_folder\"\n",
    "\n",
    "    # Output Accumulators\n",
    "    accout = Accumulator(cfg={\"info\": {\"argsdef\": {}}}, id=\"output_accumulator\", P=None)\n",
    "\n",
    "    cfg = {\"param\": \"value\"}\n",
    "    id = 1\n",
    "    P = Pipeline()\n",
    "\n",
    "    # Instantiate and run source node\n",
    "    src1 = source_aish(cfg=cfg, id=id, P=P)\n",
    "\n",
    "    try:\n",
    "        src1.run(Aout=accout, argCfg={\"data_key\": \"data\"})\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    # Output result\n",
    "    print(\"Output Accumulator Data Keys:\", accout.getDataKeys())\n",
    "    for key in accout.getDataKeys():\n",
    "        print(f\"Output Key: {key}, Value: {accout.read(key)}\")\n",
    "\n",
    "# Run the test\n",
    "test()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
